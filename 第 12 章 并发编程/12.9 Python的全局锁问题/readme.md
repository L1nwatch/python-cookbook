### 12.9 Python的全局锁问题

#### 问题

你已经听说过全局解释器锁 GIL，担心它会影响到多线程程序的执行性能。

#### 解决方案

尽管 Python 完全支持多线程编程， 但是解释器的 C 语言实现部分在完全并行执行时并不是线程安全的。 实际上，解释器被一个全局解释器锁保护着，它确保任何时候都只有一个 Python 线程执行。 GIL 最大的问题就是 Python 的多线程程序并不能利用多核 CPU 的优势 （比如一个使用了多个线程的计算密集型程序只会在一个单 CPU 上面运行）。

GIL 只会影响到那些严重依赖 CPU 的程序（比如计算型的）。 如果你的程序大部分只会涉及到 I/O，比如网络交互，那么使用多线程就很合适， 因为它们大部分时间都在等待。实际上，你完全可以放心的创建几千个 Python 线程， 现代操作系统运行这么多线程没有任何压力，没啥可担心的。

对于依赖 CPU 的程序，你需要弄清楚执行的计算的特点。 例如，优化底层算法要比使用多线程运行快得多。 类似的，由于 Python 是解释执行的，如果你将那些性能瓶颈代码移到一个 C 语言扩展模块中， 速度也会提升的很快。如果你要操作数组，那么使用 NumPy 这样的扩展会非常的高效。 最后，你还可以考虑下其他可选实现方案，比如 PyPy，它通过一个 JIT 编译器来优化执行效率。

线程不是专门用来优化性能的。 一个 CPU 依赖型程序可能会使用线程来管理一个图形用户界面、一个网络连接或其他服务。 这时候，GIL 会产生一些问题，因为如果一个线程长期持有 GIL 的话会导致其他非 CPU 型线程一直等待。 事实上，一个写的不好的 C 语言扩展会导致这个问题更加严重， 尽管代码的计算部分会比之前运行的更快些。

有两种策略来解决 GIL 的缺点。 首先，如果你完全工作于 Python 环境中，你可以使用 `multiprocessing` 模块来创建一个进程池， 并像协同处理器一样的使用它。例如，假如你有如下的线程代码：

```python
# Performs a large calculation (CPU bound)
def some_work(args):
    # ...
    return result

# A thread that calls the above function
def some_thread():
    while True:
        # ...
        r = some_work(args)
    # ...
```

修改代码，使用进程池：

```python
pool = None

def some_work(args):
    # ...
    return result

def some_thread():
    while True:
        # ...
        r = pool.apply(some_work, (args))
        # ...

if __name__ == '__main__':
    import multiprocessing
    pool = multiprocessing.Pool()
```

这个通过使用一个技巧利用进程池解决了 GIL 的问题。 当一个线程想要执行 CPU 密集型工作时，会将任务发给进程池。 然后进程池会在另外一个进程中启动一个单独的 Python 解释器来工作。 当线程等待结果的时候会释放 GIL。 并且，由于计算任务在单独解释器中执行，那么就不会受限于 GIL 了。 在一个多核系统上面，你会发现这个技术可以让你很好的利用多 CPU 的优势。

另外一个解决 GIL 的策略是使用 C 扩展编程技术。 主要思想是将计算密集型任务转移给 C，跟 Python 独立，在工作的时候在 C 代码中释放 GIL。 这可以通过在 C 代码中插入下面这样的特殊宏来完成：

```c++
#include "Python.h"
...

PyObject *pyfunc(PyObject *self, PyObject *args) {
   ...
   Py_BEGIN_ALLOW_THREADS
   // Threaded C code
   ...
   Py_END_ALLOW_THREADS
   ...
}
```

如果你使用其他工具访问 C 语言，比如对于 Cython 的 ctypes 库，你不需要做任何事。 例如，ctypes 在调用 C 时会自动释放 GIL。

#### 讨论

 作为一个真实的例子，在多线程的网络编程中神秘的 `stalls` 可能是因为其他原因比如一个 DNS 查找延时，而跟 GIL 毫无关系。 最后你真的需要先去搞懂你的代码是否真的被 GIL 影响到。 同时还要明白 GIL 大部分都应该只关注 CPU 的处理而不是 I/O。

如果你准备使用一个处理器池，注意的是这样做涉及到数据序列化和在不同 Python 解释器通信。 被执行的操作需要放在一个通过 def 语句定义的 Python 函数中，不能是 lambda、闭包可调用实例等， 并且函数参数和返回值必须要兼容 pickle。 同样，要执行的任务量必须足够大以弥补额外的通信开销。

另外一个难点是当混合使用线程和进程池的时候会让你很头疼。 如果你要同时使用两者，最好在程序启动时，创建任何线程之前先创建一个单例的进程池。然后线程使用同样的进程池来进行它们的计算密集型工作。

C 扩展最重要的特征是它们和 Python 解释器是保持独立的。 也就是说，如果你准备将 Python 中的任务分配到 C 中去执行， 你需要确保 C 代码的操作跟 Python 保持独立， 这就意味着不要使用 Python 数据结构以及不要调用 Python 的 C API。 另外一个就是你要确保 C 扩展所做的工作是足够的，值得你这样做。 也就是说 C 扩展担负起了大量的计算任务，而不是少数几个计算。

其他的解决方案，比如多进程访问共享内存区，多解析器运行于同一个进程等， 或者，你还可以考虑下其他的解释器实现，比如 PyPy。